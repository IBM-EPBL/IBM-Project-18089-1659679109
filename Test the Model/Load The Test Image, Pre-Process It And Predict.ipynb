{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAGzis88l7x8"
   },
   "source": [
    "# **Real-Time Communication System Powered By AI For Specially Abled**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3y70G0zl7Yn"
   },
   "source": [
    "**Loading the Dataset & Image Data Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iy2QXRwJeOqr"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AdFUXM70fmPj"
   },
   "outputs": [],
   "source": [
    "# Training Dataset\n",
    "train_datagen = ImageDataGenerator(rescale=1/255,zoom_range=0.2,horizontal_flip=True,vertical_flip=False)\n",
    "# Testing Dataset\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-SpHowmAgu7_",
    "outputId": "a456a77d-b9dc-47cb-b942-67453f1a81b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15750 images belonging to 9 classes.\n",
      "Found 2250 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "# Training Dataset\n",
    "x_train=train_datagen.flow_from_directory('training_set',target_size=(64,64), class_mode='categorical',batch_size=900)\n",
    "# Testing Dataset\n",
    "x_test=test_datagen.flow_from_directory('test_set',target_size=(64,64), class_mode='categorical',batch_size=900)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2qLcDqP4jgPT",
    "outputId": "4bf5a506-506c-44ac-9f13-040570b3643a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len x-train :  18\n",
      "Len x-test :  3\n"
     ]
    }
   ],
   "source": [
    "print(\"Len x-train : \", len(x_train))\n",
    "print(\"Len x-test : \", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V9Z-Rvl1jh-Q",
    "outputId": "d67bde72-545f-4820-84f5-2885822f7c10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Class Indices in Training Dataset\n",
    "x_train.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yHOh0Bhl5F9"
   },
   "source": [
    "**Model Creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ycQhnJ3om87I"
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "IVNzGYblocSh"
   },
   "outputs": [],
   "source": [
    "# Creating Model\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "G7kEjSISpDs7"
   },
   "outputs": [],
   "source": [
    "# Adding Convolution Layers\n",
    "model.add(Convolution2D(32,(3,3),activation='relu',input_shape=(64,64,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "p8lwdE26pLdN"
   },
   "outputs": [],
   "source": [
    "# Adding Pool Layers\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cIeLXS77pTEq"
   },
   "outputs": [],
   "source": [
    "# Adding Flatten Layers\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0XAR5Q0fphqp"
   },
   "outputs": [],
   "source": [
    "# Adding Dense Layers\n",
    "model.add(Dense(300,activation='relu'))\n",
    "model.add(Dense(150,activation='relu'))\n",
    "model.add(Dense(9,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Pvo6cZAVpsiT"
   },
   "outputs": [],
   "source": [
    "# Compiling the Model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1tPmi7ap5yd",
    "outputId": "fe240748-001e-43ab-f0cc-3e955747250a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91936\\AppData\\Local\\Temp/ipykernel_1340/1042518445.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(x_train,steps_per_epoch=len(x_train),epochs=10,validation_data=x_test,validation_steps=len(x_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18/18 [==============================] - 34s 2s/step - loss: 0.8681 - accuracy: 0.7029 - val_loss: 0.2913 - val_accuracy: 0.9187\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 34s 2s/step - loss: 0.1690 - accuracy: 0.9523 - val_loss: 0.2492 - val_accuracy: 0.9529\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 36s 2s/step - loss: 0.0685 - accuracy: 0.9823 - val_loss: 0.1681 - val_accuracy: 0.9716\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.0345 - accuracy: 0.9918 - val_loss: 0.2067 - val_accuracy: 0.9764\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.0201 - accuracy: 0.9942 - val_loss: 0.2200 - val_accuracy: 0.9760\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 39s 2s/step - loss: 0.0120 - accuracy: 0.9977 - val_loss: 0.2369 - val_accuracy: 0.9769\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 40s 2s/step - loss: 0.0089 - accuracy: 0.9980 - val_loss: 0.2407 - val_accuracy: 0.9778\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 40s 2s/step - loss: 0.0063 - accuracy: 0.9989 - val_loss: 0.2169 - val_accuracy: 0.9773\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.2632 - val_accuracy: 0.9773\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.2710 - val_accuracy: 0.9773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226b0e04d30>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the Model Generator\n",
    "model.fit_generator(x_train,steps_per_epoch=len(x_train),epochs=10,validation_data=x_test,validation_steps=len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jB3lpZWWIBi9"
   },
   "source": [
    "**Saving the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "model.save('aslpng1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary packages\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the saved model\n",
    "model=load_model('aslpng1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAC2ElEQVR4nO2Zv2vyQBjH716khEayZEgt2MUltGChQ3FpRSg09B+oSzLnT7Cgc+IgHTp2c7FThoLY1f9A0FlKoerSIQ4qErgOed+8eW2sMffDt3CfKd4lzz3fu+d+PCcAHA6Hw+FwOBwOh8PhcH4kcF1FuVwOnp+enpg4g4eiKIPBwDRN0zQdx0Gx6Xa7pmnGb8hv4uXl5fj4GN/tvyOAEMI3d3d3BwBoNpuj0SgorFQq/oNlWV8/yeVyw+EwcYuEBSTGtm3wR39C6vV6/LChhCAIWN1gWdauJaD5fI6lIZPJ7FoCQgg9Pj5iyQijqmq/39+JjPv7+43urd0HvgExnO4QbvDwFw2jBNnYWUkEAABOT0+TfUichAKWyyVZP74BIZRKpajYZcbDw0NctyRJUlVVVVX/y3a77f/c29vboYBYrqfT6Y2GCoVC8H6hUKDh63w+v7m56fV64UJd10mGhKZp/88gwMCVWMPEkI+PD1mWwyWRy3fCVYgqs9kMQnhychIuPDs7i3z5twCSZw88PM8TRbHRaEwmk3D59fV15Pv/DEqQeRSLxSDQWVKr1Wzb9jwvMqS3PgFcXl6ynKbBZK3X68E6/rV2a8rlMksBgiAghFzXjWw3Ylhiynh7e8tms0k6YEsghH70djqdyFos6wxGAAAgy/LKRhZwdXWFJYCBBj+E1vH+/n5xcRH2Z+t9AEKYz+dxu2E9iqJ8U3t4eLi/vx8uSbKR9ft9evnA6+srJcurnJ+f0w6nr9ze3j4/PxPTUCqV2GtY8YFAdjsejw8ODvDtxGRlJSVwmMtkMoZh4NtJBsn7BZabXfBM8jh9dHTE5p+EVqtF0TqDeRzObMknNCyvvQCljAxCiHXTH4OVbJMKhmFQCiHHcah7H6DrOg0N7AT4aJr2swX4kL0L820yXTEAAJIkua5LxJS/3LG+F5pOp6IoEjHF8gC2SrVaxQ+hxWIBAPgEeZeJEkEn4jcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x226AAB290D0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the test image\n",
    "test_image=image.load_img('test_set/G/162.png',\n",
    "                   target_size=(64,64))\n",
    "test_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image to array conversion\n",
    "tmp=image.img_to_array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Dimension before expansion 3\n",
      "Image Dimension after expansion 4\n"
     ]
    }
   ],
   "source": [
    "#Image Dimension expansion\n",
    "print('Image Dimension before expansion',tmp.ndim)\n",
    "tmp=np.expand_dims(tmp,axis=0)\n",
    "print('Image Dimension after expansion',tmp.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G\n"
     ]
    }
   ],
   "source": [
    "prediction=np.argmax(model.predict(tmp),axis=1)\n",
    "index=['A','B','C','D','E','F','G','H','I']\n",
    "print(index[prediction[0]])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
