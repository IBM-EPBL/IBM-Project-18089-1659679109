{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAGzis88l7x8"
   },
   "source": [
    "# **Real-Time Communication System Powered By AI For Specially Abled**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3y70G0zl7Yn"
   },
   "source": [
    "**Loading the Dataset & Image Data Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.0'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "cos_client = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='ErVrjDC4qbmR1KaZotX54AAbOcw1lsNAQYG-B3x3Sw7r',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n",
    "\n",
    "bucket = 'handgesturerecognition-donotdelete-pr-hhsthql6vq5etp'\n",
    "object_key = 'Dataset.zip'\n",
    "\n",
    "streaming_body_1 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n",
    "\n",
    "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
    "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
    "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
    "# pandas documentation: http://pandas.pydata.org/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import zipfile\n",
    "unzip = zipfile.ZipFile(BytesIO(streaming_body_1.read()),'r')\n",
    "file_paths = unzip.namelist()\n",
    "for path in file_paths:\n",
    "    unzip.extract(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wsuser/work'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filenames = os.listdir('/home/wsuser/work/Data Collection/test_set/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Dataset\n",
    "train_datagen = ImageDataGenerator(rescale=1/255,zoom_range=0.2,horizontal_flip=True,vertical_flip=False)\n",
    "# Testing Dataset\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-SpHowmAgu7_",
    "outputId": "a456a77d-b9dc-47cb-b942-67453f1a81b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15750 images belonging to 9 classes.\n",
      "Found 2250 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "# Training Dataset\n",
    "x_train=train_datagen.flow_from_directory('/home/wsuser/work/Data Collection/training_set/',target_size=(64,64), class_mode='categorical',batch_size=900)\n",
    "# Testing Dataset\n",
    "x_test=test_datagen.flow_from_directory('/home/wsuser/work/Data Collection/test_set/',target_size=(64,64), class_mode='categorical',batch_size=900)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2qLcDqP4jgPT",
    "outputId": "4bf5a506-506c-44ac-9f13-040570b3643a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len x-train :  18\n",
      "Len x-test :  3\n"
     ]
    }
   ],
   "source": [
    "print(\"Len x-train : \", len(x_train))\n",
    "print(\"Len x-test : \", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V9Z-Rvl1jh-Q",
    "outputId": "d67bde72-545f-4820-84f5-2885822f7c10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Class Indices in Training Dataset\n",
    "x_train.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yHOh0Bhl5F9"
   },
   "source": [
    "**Model Creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "ycQhnJ3om87I"
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "IVNzGYblocSh"
   },
   "outputs": [],
   "source": [
    "# Creating Model\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "G7kEjSISpDs7"
   },
   "outputs": [],
   "source": [
    "# Adding Convolution Layers\n",
    "model.add(Convolution2D(32,(3,3),activation='relu',input_shape=(64,64,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "p8lwdE26pLdN"
   },
   "outputs": [],
   "source": [
    "# Adding Pool Layers\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "cIeLXS77pTEq"
   },
   "outputs": [],
   "source": [
    "# Adding Flatten Layers\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "0XAR5Q0fphqp"
   },
   "outputs": [],
   "source": [
    "# Adding Dense Layers\n",
    "model.add(Dense(300,activation='relu'))\n",
    "model.add(Dense(150,activation='relu'))\n",
    "model.add(Dense(9,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "Pvo6cZAVpsiT"
   },
   "outputs": [],
   "source": [
    "# Compiling the Model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/wsuser/ipykernel_164/3484864488.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(x_train,steps_per_epoch=18,epochs=10,validation_data=x_test,validation_steps=40)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9992WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 40 batches). You may need to use the repeat() function when building your dataset.\n",
      "18/18 [==============================] - 75s 4s/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.2708 - val_accuracy: 0.9760\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 70s 4s/step - loss: 0.0043 - accuracy: 0.9989\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 70s 4s/step - loss: 0.0033 - accuracy: 0.9996\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 71s 4s/step - loss: 0.0030 - accuracy: 0.9996\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 71s 4s/step - loss: 0.0026 - accuracy: 0.9996\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 72s 4s/step - loss: 0.0022 - accuracy: 0.9996\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 71s 4s/step - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 73s 4s/step - loss: 0.0014 - accuracy: 0.9998\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 70s 4s/step - loss: 0.0011 - accuracy: 0.9999\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 70s 4s/step - loss: 0.0012 - accuracy: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff34ef8b160>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the Model Generator\n",
    "model.fit_generator(x_train,steps_per_epoch=18,epochs=10,validation_data=x_test,validation_steps=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jB3lpZWWIBi9"
   },
   "source": [
    "**Saving the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "model.save('aslpng1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aslpng1.h5\r\n"
     ]
    }
   ],
   "source": [
    "!tar -zcvf hand-gesture-recognition-model.tgz aslpng1.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " aslpng1.h5  \u001b[0m\u001b[01;34m'Data Collection'\u001b[0m/   hand-gesture-recognition-model.tgz\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: watson-machine-learning-client in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (1.0.391)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from watson-machine-learning-client) (4.64.0)\n",
      "Requirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from watson-machine-learning-client) (2.12.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from watson-machine-learning-client) (2.28.1)\n",
      "Requirement already satisfied: tabulate in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from watson-machine-learning-client) (0.8.10)\n",
      "Requirement already satisfied: lomond in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from watson-machine-learning-client) (0.3.3)\n",
      "Requirement already satisfied: boto3 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from watson-machine-learning-client) (1.24.28)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from watson-machine-learning-client) (2022.9.24)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from watson-machine-learning-client) (1.26.11)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from watson-machine-learning-client) (1.4.3)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.28 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from boto3->watson-machine-learning-client) (1.27.28)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from boto3->watson-machine-learning-client) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from boto3->watson-machine-learning-client) (0.10.0)\n",
      "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.12.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.12.0)\n",
      "Requirement already satisfied: ibm-cos-sdk-core==2.12.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.12.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-cos-sdk-core==2.12.0->ibm-cos-sdk->watson-machine-learning-client) (2.8.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests->watson-machine-learning-client) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests->watson-machine-learning-client) (2.0.4)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from lomond->watson-machine-learning-client) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from pandas->watson-machine-learning-client) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from pandas->watson-machine-learning-client) (1.23.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install watson-machine-learning-client --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient\n",
    "wml_credentials = {\n",
    "                    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "                    \"apikey\":\"ylO-swSSvJcDO5mEeIXURwD1NhePCF5BYrKtuByI2QH3\"\n",
    "                }\n",
    "client = APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guid_from_space_name(client,space_name):\n",
    "    space = client.spaces.get_details()\n",
    "    return(next(item for item in space['resources'] if item['entity']['name'] == space_name)['metadata']['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0b293060-2bce-4f00-b71f-cb1e0cc18c72'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space_uid = guid_from_space_name(client,'Hand Gesture Recognition')\n",
    "space_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.set.default_space(space_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------  ------------------------------------  ----\n",
      "NAME                           ASSET_ID                              TYPE\n",
      "default_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\n",
      "kernel-spark3.2-scala2.12      020d69ce-7ac1-5e68-ac1a-31189867356a  base\n",
      "pytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base\n",
      "scikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\n",
      "spark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\n",
      "pytorch-onnx_rt22.1-py3.9      0b848dd4-e681-5599-be41-b5f6fccc6471  base\n",
      "ai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\n",
      "shiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base\n",
      "tensorflow_2.4-py3.7-horovod   1092590a-307d-563d-9b62-4eb7d64b3f22  base\n",
      "pytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base\n",
      "tensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base\n",
      "autoai-kb_rt22.2-py3.10        125b6d9a-5b1f-5e8d-972a-b251688ccf40  base\n",
      "runtime-22.1-py3.9             12b83a17-24d8-5082-900f-0ab31fbfd3cb  base\n",
      "scikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\n",
      "default_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\n",
      "pytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\n",
      "kernel-spark3.3-r3.6           1c9e5454-f216-59dd-a20e-474a5cdf5988  base\n",
      "pytorch-onnx_rt22.1-py3.9-edt  1d362186-7ad5-5b59-8b6c-9d0880bde37f  base\n",
      "tensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\n",
      "spark-mllib_3.2                20047f72-0a98-58c7-9ff5-a77b012eb8f5  base\n",
      "tensorflow_2.4-py3.8-horovod   217c16f6-178f-56bf-824a-b19f20564c49  base\n",
      "runtime-22.1-py3.9-cuda        26215f05-08c3-5a41-a1b0-da66306ce658  base\n",
      "do_py3.8                       295addb5-9ef9-547e-9bf4-92ae3563e720  base\n",
      "autoai-ts_3.8-py3.8            2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base\n",
      "tensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base\n",
      "kernel-spark3.3-py3.9          2b7961e2-e3b1-5a8c-a491-482c8368839a  base\n",
      "pytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base\n",
      "spark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base\n",
      "pytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base\n",
      "spark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base\n",
      "spark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base\n",
      "autoai-ts_rt22.2-py3.10        396b2e83-0953-5b86-9a55-7ce1628a406f  base\n",
      "xgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base\n",
      "pytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\n",
      "pytorch-onnx_rt22.2-py3.10     40e73f55-783a-5535-b3fa-0c8b94291431  base\n",
      "default_r36py38                41c247d3-45f8-5a71-b065-8580229facf0  base\n",
      "autoai-ts_rt22.1-py3.9         4269d26e-07ba-5d40-8f66-2d495b0c71f7  base\n",
      "autoai-obm_3.0                 42b92e18-d9ab-567f-988a-4240ba1ed5f7  base\n",
      "pmml-3.0_4.3                   493bcb95-16f1-5bc5-bee8-81b8af80e9c7  base\n",
      "spark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base\n",
      "xgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base\n",
      "pytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\n",
      "autoai-ts_3.9-py3.8            52c57136-80fa-572e-8728-a5e7cbb42cde  base\n",
      "spark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base\n",
      "spark-mllib_3.0                5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base\n",
      "autoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base\n",
      "spss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\n",
      "cuda-py3.8                     5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base\n",
      "runtime-22.2-py3.10-xc         5e8cddff-db4a-5a6a-b8aa-2d4af9864dab  base\n",
      "autoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base\n",
      "-----------------------------  ------------------------------------  ----\n",
      "Note: Only first 50 records were displayed. To display more use 'limit' parameter.\n"
     ]
    }
   ],
   "source": [
    "client.software_specifications.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'acd9c798-6974-5d2f-a657-ce06e986df4d'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "software_spec_uid = client.software_specifications.get_uid_by_name(\"tensorflow_rt22.1-py3.9\")\n",
    "software_spec_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " aslpng1.h5  \u001b[0m\u001b[01;34m'Data Collection'\u001b[0m/   hand-gesture-recognition-model.tgz\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_details=client.repository.store_model(model=\"hand-gesture-recognition-model.tgz\",meta_props={\n",
    "    client.repository.ModelMetaNames.NAME: \"CNN_gesture_recognition\",\n",
    "    client.repository.ModelMetaNames.TYPE: \"tensorflow_2.7\",\n",
    "    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID:software_spec_uid\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity': {'hybrid_pipeline_software_specs': [],\n",
       "  'software_spec': {'id': 'acd9c798-6974-5d2f-a657-ce06e986df4d',\n",
       "   'name': 'tensorflow_rt22.1-py3.9'},\n",
       "  'type': 'tensorflow_2.7'},\n",
       " 'metadata': {'created_at': '2022-11-22T17:24:10.143Z',\n",
       "  'id': 'e1e6e4dc-e38c-4270-a44d-d498b54df3a7',\n",
       "  'modified_at': '2022-11-22T17:24:18.673Z',\n",
       "  'name': 'CNN_gesture_recognition',\n",
       "  'owner': 'IBMid-666002GA2D',\n",
       "  'resource_key': 'ef2eeac3-61eb-4efa-ab42-dd0f3ff16f1a',\n",
       "  'space_id': '0b293060-2bce-4f00-b71f-cb1e0cc18c72'},\n",
       " 'system': {'warnings': []}}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e1e6e4dc-e38c-4270-a44d-d498b54df3a7'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id=client.repository.get_model_id(model_details)\n",
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------  -----------------------  ------------------------  --------------  -----\n",
      "GUID                                  NAME                     CREATED                   FRAMEWORK       TYPE\n",
      "e1e6e4dc-e38c-4270-a44d-d498b54df3a7  CNN_gesture_recognition  2022-11-22T17:24:10.002Z  tensorflow_2.7  model\n",
      "------------------------------------  -----------------------  ------------------------  --------------  -----\n"
     ]
    }
   ],
   "source": [
    "client.repository.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model content to file: 'gesture-recognition-model.tgz'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/wsuser/work/gesture-recognition-model.tgz'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id=\"e1e6e4dc-e38c-4270-a44d-d498b54df3a7\"\n",
    "client.repository.download(model_id,\"gesture-recognition-model.tgz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary packages\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the saved model\n",
    "model=load_model('aslpng1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAC2ElEQVR4nO2Zv2vyQBjH716khEayZEgt2MUltGChQ3FpRSg09B+oSzLnT7Cgc+IgHTp2c7FThoLY1f9A0FlKoerSIQ4qErgOed+8eW2sMffDt3CfKd4lzz3fu+d+PCcAHA6Hw+FwOBwOh8PhcH4kcF1FuVwOnp+enpg4g4eiKIPBwDRN0zQdx0Gx6Xa7pmnGb8hv4uXl5fj4GN/tvyOAEMI3d3d3BwBoNpuj0SgorFQq/oNlWV8/yeVyw+EwcYuEBSTGtm3wR39C6vV6/LChhCAIWN1gWdauJaD5fI6lIZPJ7FoCQgg9Pj5iyQijqmq/39+JjPv7+43urd0HvgExnO4QbvDwFw2jBNnYWUkEAABOT0+TfUichAKWyyVZP74BIZRKpajYZcbDw0NctyRJUlVVVVX/y3a77f/c29vboYBYrqfT6Y2GCoVC8H6hUKDh63w+v7m56fV64UJd10mGhKZp/88gwMCVWMPEkI+PD1mWwyWRy3fCVYgqs9kMQnhychIuPDs7i3z5twCSZw88PM8TRbHRaEwmk3D59fV15Pv/DEqQeRSLxSDQWVKr1Wzb9jwvMqS3PgFcXl6ynKbBZK3X68E6/rV2a8rlMksBgiAghFzXjWw3Ylhiynh7e8tms0k6YEsghH70djqdyFos6wxGAAAgy/LKRhZwdXWFJYCBBj+E1vH+/n5xcRH2Z+t9AEKYz+dxu2E9iqJ8U3t4eLi/vx8uSbKR9ft9evnA6+srJcurnJ+f0w6nr9ze3j4/PxPTUCqV2GtY8YFAdjsejw8ODvDtxGRlJSVwmMtkMoZh4NtJBsn7BZabXfBM8jh9dHTE5p+EVqtF0TqDeRzObMknNCyvvQCljAxCiHXTH4OVbJMKhmFQCiHHcah7H6DrOg0N7AT4aJr2swX4kL0L820yXTEAAJIkua5LxJS/3LG+F5pOp6IoEjHF8gC2SrVaxQ+hxWIBAPgEeZeJEkEn4jcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the test image\n",
    "test_image=image.load_img('/home/wsuser/work/Data Collection/test_set/G/162.png',\n",
    "                   target_size=(64,64))\n",
    "test_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image to array conversion\n",
    "tmp=image.img_to_array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Dimension before expansion 3\n",
      "Image Dimension after expansion 4\n"
     ]
    }
   ],
   "source": [
    "#Image Dimension expansion\n",
    "print('Image Dimension before expansion',tmp.ndim)\n",
    "tmp=np.expand_dims(tmp,axis=0)\n",
    "print('Image Dimension after expansion',tmp.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step\n",
      "G\n"
     ]
    }
   ],
   "source": [
    "prediction=np.argmax(model.predict(tmp),axis=1)\n",
    "index=['A','B','C','D','E','F','G','H','I']\n",
    "print(index[prediction[0]])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
